{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLfnujch4uHWxpwhmhNmDL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naomy-Yailin/SIS420/blob/main/laboratorio3/reg_log_onevsall_lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Este conjunto de datos consta de 101 animales de un zoológico.\n",
        "# Hay 16 variables con varios rasgos para describir a los animales. **texto en negrita**\n",
        "# Los 7 tipos de clase son: Mamífero, Ave, Reptil, Pez, Anfibio, Insecto e Invertebrado **texto en negrita**\n",
        "\n",
        "# El propósito de este conjunto de datos es poder predecir la clasificación de los animales, en función de las variables. **texto en negrita**"
      ],
      "metadata": {
        "id": "nMeQ-YxWBufv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDH3MmzOwUST",
        "outputId": "7ee84236-c1a3-4418-a017-2f3942eef6c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utilizado para la manipulación de directorios y rutas\n",
        "import os\n",
        "\n",
        "# Cálculo científico y vectorial para python\n",
        "import numpy as np\n",
        "\n",
        "# Libreria para graficos\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# Modulo de optimizacion en scipy\n",
        "from scipy import optimize\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# modulo para cargar archivos en formato MATLAB\n",
        "# from scipy.io import loadmat\n",
        "\n",
        "# le dice a matplotlib que incruste gráficos en el cuaderno\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "t9oIAtCfwgwe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar dataset Zoo\n",
        "data = pd.read_csv('/content/zoo.csv')\n",
        "\n",
        "# Extraer X (características) y y (etiquetas)\n",
        "X = data.iloc[:, 1:-1].values   # todas las columnas menos 'animal_name' y 'class_type'\n",
        "y = data.iloc[:, -1].values     # columna class_type\n",
        "\n",
        "# Definir número de entradas y salidas\n",
        "# Hay 16 atributos en el dataset, pero el comentario original contaba x0 (bias)\n",
        "input_layer_size = X.shape[1] + 1   # 16 + 1 = 17\n",
        "num_labels = len(np.unique(y))      # 7 clases distintas\n",
        "\n",
        "# Ajustar etiquetas: pasar de 1-7 a 0-6 para evitar problemas\n",
        "y = y - 1\n",
        "\n",
        "# Número de ejemplos de entrenamiento\n",
        "m = y.size\n",
        "\n",
        "print(\"Número de ejemplos:\", m)\n",
        "print(\"Dimensión de X:\", X.shape)\n",
        "print(\"Clases distintas:\", num_labels)\n",
        "print(\"Primeras etiquetas:\", y[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4ouLimQ3xIe",
        "outputId": "5cc60a5a-20cb-4e56-b87d-12872e9f8456"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de ejemplos: 101\n",
            "Dimensión de X: (101, 16)\n",
            "Clases distintas: 7\n",
            "Primeras etiquetas: [0 0 3 0 0 0 0 3 3 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[0,:])\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob-4Vvly6vNV",
        "outputId": "3409427d-a512-4c20-d5ca-09bb24f3a99b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 0 0 1 1 1 1 0 0 4 0 0 1]\n",
            "[0 0 3 0 0 0 0 3 3 0 0 1 3 6 6 6 1 0 3 0 1 1 0 1 5 4 4 0 0 0 5 0 0 1 3 0 0\n",
            " 1 3 5 5 1 5 1 0 0 6 0 0 0 0 5 4 6 0 0 1 1 1 1 3 3 2 0 0 0 0 0 0 0 0 1 6 3\n",
            " 0 0 2 6 1 1 2 6 3 1 0 6 3 1 5 4 2 2 3 0 0 1 0 5 0 6 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def featureNormalize(X):\n",
        "    mu = np.mean(X, axis=0)\n",
        "    sigma = np.std(X, axis=0, ddof=1)  # ddof=1 para desviación estándar muestral\n",
        "    X_norm = (X - mu) / sigma\n",
        "    return X_norm, mu, sigma\n",
        "\n",
        "# Aplicar a tu dataset zoo\n",
        "X_norm, mu, sigma = featureNormalize(X)\n",
        "\n",
        "print(\"Primer ejemplo normalizado:\", X_norm[0,:])\n",
        "print(\"Medias:\", mu)\n",
        "print(\"Desviaciones estándar:\", sigma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyFonvCD7M-v",
        "outputId": "1120640c-fea4-4aed-edc2-14947e3d98d1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primer ejemplo normalizado: [ 1.15563073 -0.49443795 -1.17934447  1.20371316 -0.55551984 -0.74051504\n",
            "  0.89197269  0.80575756  0.46337918  0.50980485 -0.29183867 -0.4476351\n",
            "  0.56969831 -1.68998664 -0.38244559  1.13253179]\n",
            "Medias: [0.42574257 0.1980198  0.58415842 0.40594059 0.23762376 0.35643564\n",
            " 0.55445545 0.6039604  0.82178218 0.79207921 0.07920792 0.16831683\n",
            " 2.84158416 0.74257426 0.12871287 0.43564356]\n",
            "Desviaciones estándar: [0.49692121 0.40049474 0.49532468 0.4935224  0.42775027 0.48133478\n",
            " 0.49950471 0.49151211 0.38460472 0.40784388 0.27140996 0.37601348\n",
            " 2.03338473 0.43939653 0.33655212 0.49831399]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llama featureNormalize con los datos cargados\n",
        "X_norm, mu, sigma = featureNormalize(X)"
      ],
      "metadata": {
        "id": "YCQXQNCU7TCc"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_norm[0,:])\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8dciwRO7luC",
        "outputId": "60d568ef-6d00-4301-d66d-2c8771bf619b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.15563073 -0.49443795 -1.17934447  1.20371316 -0.55551984 -0.74051504\n",
            "  0.89197269  0.80575756  0.46337918  0.50980485 -0.29183867 -0.4476351\n",
            "  0.56969831 -1.68998664 -0.38244559  1.13253179]\n",
            "[0 0 3 0 0 0 0 3 3 0 0 1 3 6 6 6 1 0 3 0 1 1 0 1 5 4 4 0 0 0 5 0 0 1 3 0 0\n",
            " 1 3 5 5 1 5 1 0 0 6 0 0 0 0 5 4 6 0 0 1 1 1 1 3 3 2 0 0 0 0 0 0 0 0 1 6 3\n",
            " 0 0 2 6 1 1 2 6 3 1 0 6 3 1 5 4 2 2 3 0 0 1 0 5 0 6 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar la matriz adecuadamente, y agregar una columna de unos que corresponde al termino de intercepción.\n",
        "m, n = X.shape\n",
        "# Agraga el termino de intercepción a A\n",
        "# X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)\n",
        "X = X_norm\n",
        "# X = np.concatenate([np.ones((m, 1)), X], axis=1)"
      ],
      "metadata": {
        "id": "sNh64zhD7xge"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Vectorización de regresión logística\n",
        "\n",
        "Se utilizará múltiples modelos de regresión logística uno contra todos para construir un clasificador de clases múltiples. Dado que hay 10 clases, deberá entrenar 10 clasificadores de regresión logística separados. Para que esta capacitación sea eficiente, es importante asegurarse de que el código esté bien vectorizado.\n",
        "\n",
        "En esta sección, se implementará una versión vectorizada de regresión logística que no emplea ningún bucle \"for\".\n",
        "\n",
        "Para probar la regresión logística vectorizada, se usara datos personalizados como se definen a continuación."
      ],
      "metadata": {
        "id": "I8OxTQj1BR9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"section1\"></a>\n",
        "#### 1.3.1 Vectorización de la funcion de costo\n",
        "\n",
        "Se inicia escribiendo una versión vectorizada de la función de costo. En la regresión logística (no regularizada), la función de costo es\n",
        "\n",
        "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\left[ -y^{(i)} \\log \\left( h_\\theta\\left( x^{(i)} \\right) \\right) - \\left(1 - y^{(i)} \\right) \\log \\left(1 - h_\\theta \\left( x^{(i)} \\right) \\right) \\right] $$\n",
        "\n",
        "Para calcular cada elemento en la suma, tenemos que calcular $h_\\theta(x^{(i)})$ para cada ejemplo $i$, donde $h_\\theta(x^{(i)}) = g(\\theta^T x^{(i)})$ y $g(z) = \\frac{1}{1+e^{-z}}$ es la funcion sigmoidea. Resulta que podemos calcular esto rápidamente para todos los ejemplos usando la multiplicación de matrices. Definamos $X$ y $\\theta$ como\n",
        "\n",
        "$$ X = \\begin{bmatrix} - \\left( x^{(1)} \\right)^T - \\\\ - \\left( x^{(2)} \\right)^T - \\\\ \\vdots \\\\ - \\left( x^{(m)} \\right)^T - \\end{bmatrix} \\qquad \\text{and} \\qquad \\theta = \\begin{bmatrix} \\theta_0 \\\\ \\theta_1 \\\\ \\vdots \\\\ \\theta_n \\end{bmatrix} $$\n",
        "\n",
        "Luego, de calcular el producto matricial $X\\theta$, se tiene:\n",
        "\n",
        "$$ X\\theta = \\begin{bmatrix} - \\left( x^{(1)} \\right)^T\\theta - \\\\ - \\left( x^{(2)} \\right)^T\\theta - \\\\ \\vdots \\\\ - \\left( x^{(m)} \\right)^T\\theta - \\end{bmatrix} = \\begin{bmatrix} - \\theta^T x^{(1)}  - \\\\ - \\theta^T x^{(2)} - \\\\ \\vdots \\\\ - \\theta^T x^{(m)}  - \\end{bmatrix} $$\n",
        "\n",
        "En la última igualdad, usamos el hecho de que $a^Tb = b^Ta$ if $a$ y $b$ son vectores. Esto permite calcular los productos $\\theta^T x^{(i)}$ para todos los ejemplos $i$ en una linea de codigo.\n",
        "\n",
        "#### 1.3.2 Vectorización del gradiente\n",
        "\n",
        "Recordemos que el gradiente del costo de regresión logística (no regularizado) es un vector donde el elemento $j^{th}$ se define como\n",
        "$$ \\frac{\\partial J }{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^m \\left( \\left( h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x_j^{(i)} \\right) $$\n",
        "\n",
        "Para vectorizar esta operación sobre el conjunto de datos, se inicia escribiendo todas las derivadas parciales explícitamente para todos $\\theta_j$,\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\begin{bmatrix}\n",
        "\\frac{\\partial J}{\\partial \\theta_0} \\\\\n",
        "\\frac{\\partial J}{\\partial \\theta_1} \\\\\n",
        "\\frac{\\partial J}{\\partial \\theta_2} \\\\\n",
        "\\vdots \\\\\n",
        "\\frac{\\partial J}{\\partial \\theta_n}\n",
        "\\end{bmatrix} = &\n",
        "\\frac{1}{m} \\begin{bmatrix}\n",
        "\\sum_{i=1}^m \\left( \\left(h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x_0^{(i)}\\right) \\\\\n",
        "\\sum_{i=1}^m \\left( \\left(h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x_1^{(i)}\\right) \\\\\n",
        "\\sum_{i=1}^m \\left( \\left(h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x_2^{(i)}\\right) \\\\\n",
        "\\vdots \\\\\n",
        "\\sum_{i=1}^m \\left( \\left(h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x_n^{(i)}\\right) \\\\\n",
        "\\end{bmatrix} \\\\\n",
        "= & \\frac{1}{m} \\sum_{i=1}^m \\left( \\left(h_\\theta\\left(x^{(i)}\\right) - y^{(i)} \\right)x^{(i)}\\right) \\\\\n",
        "= & \\frac{1}{m} X^T \\left( h_\\theta(x) - y\\right)\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "donde\n",
        "\n",
        "$$  h_\\theta(x) - y =\n",
        "\\begin{bmatrix}\n",
        "h_\\theta\\left(x^{(1)}\\right) - y^{(1)} \\\\\n",
        "h_\\theta\\left(x^{(2)}\\right) - y^{(2)} \\\\\n",
        "\\vdots \\\\\n",
        "h_\\theta\\left(x^{(m)}\\right) - y^{(m)}\n",
        "\\end{bmatrix} $$\n",
        "\n",
        "Nota $x^{(i)}$ es un vector, mientras $h_\\theta\\left(x^{(i)}\\right) - y^{(i)}$ es un escalar(simple número).\n",
        "Para comprender el último paso de la derivación, dejemos $\\beta_i = (h_\\theta\\left(x^{(m)}\\right) - y^{(m)})$ y\n",
        "observar que:\n",
        "\n",
        "$$ \\sum_i \\beta_ix^{(i)} = \\begin{bmatrix}\n",
        "| & | & & | \\\\\n",
        "x^{(1)} & x^{(2)} & \\cdots & x^{(m)} \\\\\n",
        "| & | & & |\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "\\beta_1 \\\\\n",
        "\\beta_2 \\\\\n",
        "\\vdots \\\\\n",
        "\\beta_m\n",
        "\\end{bmatrix} = x^T \\beta\n",
        "$$\n",
        "\n",
        "donde los valores $\\beta_i = \\left( h_\\theta(x^{(i)} - y^{(i)} \\right)$.\n",
        "\n",
        "La expresión anterior nos permite calcular todas las derivadas parciales sin bucles.\n",
        "Si se siente cómodo con el álgebra lineal, le recomendamos que trabaje con las multiplicaciones de matrices anteriores para convencerse de que la versión vectorizada hace los mismos cálculos.\n",
        "\n",
        "<div class=\"alert alert-box alert-warning\">\n",
        "** Consejo de depuración: ** El código de vectorización a veces puede ser complicado. Una estrategia común para la depuración es imprimir los tamaños de las matrices con las que está trabajando usando la propiedad `shape` de las matrices` numpy`.\n",
        "\n",
        "Por ejemplo, dada una matriz de datos $X$ de tamaño $100\\veces 20$ (100 ejemplos, 20 características) y $\\theta$, un vector con tamaño $20$, puede observar que `np.dot (X, theta) `es una operación de multiplicación válida, mientras que` np.dot (theta, X) `no lo es.\n",
        "\n",
        "Además, si tiene una versión no vectorizada de su código, puede comparar la salida de su código vectorizado y el código no vectorizado para asegurarse de que produzcan las mismas salidas.</div>\n",
        "<a id=\"lrCostFunction\"></a>"
      ],
      "metadata": {
        "id": "IM-0FVcC8HFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    Calcula la sigmoide de z.\n",
        "    \"\"\"\n",
        "    return 1.0 / (1.0 + np.exp(-z))"
      ],
      "metadata": {
        "id": "oe5w6DxC8Hd4"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calcularCosto(theta, X, y):\n",
        "    # Inicializar algunos valores utiles\n",
        "    m = y.size  # numero de ejemplos de entrenamiento\n",
        "\n",
        "    J = 0\n",
        "    h = sigmoid(X.dot(theta.T))\n",
        "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n",
        "\n",
        "    return J"
      ],
      "metadata": {
        "id": "EiSoO84E8GY6"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def descensoGradiente(theta, X, y, alpha, num_iters):\n",
        "    # Inicializa algunos valores\n",
        "    m = y.shape[0] # numero de ejemplos de entrenamiento\n",
        "\n",
        "    # realiza una copia de theta, el cual será acutalizada por el descenso por el gradiente\n",
        "    theta = theta.copy()\n",
        "    J_history = []\n",
        "\n",
        "    for i in range(num_iters):\n",
        "        h = sigmoid(X.dot(theta.T))\n",
        "        theta = theta - (alpha / m) * (h - y).dot(X)\n",
        "\n",
        "        J_history.append(calcularCosto(theta, X, y))\n",
        "    return theta, J_history"
      ],
      "metadata": {
        "id": "F_MI0rrG8Vei"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lrCostFunction(theta, X, y, lambda_):\n",
        "    \"\"\"\n",
        "    Calcula el costo de usar theta como parámetro para la regresión logística regularizada y\n",
        "    el gradiente del costo w.r.t. a los parámetros.\n",
        "\n",
        "    Parametros\n",
        "    ----------\n",
        "    theta : array_like\n",
        "        Parametro theta de la regresion logistica. Vector de la forma(shape) (n, ). n es el numero de caracteristicas\n",
        "        incluida la intercepcion\n",
        "\n",
        "    X : array_like\n",
        "        Dataset con la forma(shape) (m x n). m es el numero de ejemplos, y n es el numero de\n",
        "        caracteristicas (incluida la intercepcion).\n",
        "\n",
        "    y : array_like\n",
        "        El conjunto de etiquetas. Un vector con la forma (shape) (m, ). m es el numero de ejemplos\n",
        "\n",
        "    lambda_ : float\n",
        "        Parametro de regularización.\n",
        "\n",
        "    Devuelve\n",
        "    -------\n",
        "    J : float\n",
        "        El valor calculado para la funcion de costo regularizada.\n",
        "\n",
        "    grad : array_like\n",
        "        Un vector de la forma (shape) (n, ) que es el gradiente de la\n",
        "        función de costo con respecto a theta, en los valores actuales de theta..\n",
        "    \"\"\"\n",
        "#     alpha = 0.003\n",
        "#     theta = theta.copy()\n",
        "    # Inicializa algunos valores utiles\n",
        "    m = y.size\n",
        "\n",
        "    # convierte las etiquetas a valores enteros si son boleanos\n",
        "    if y.dtype == bool:\n",
        "        y = y.astype(int)\n",
        "\n",
        "    J = 0\n",
        "    grad = np.zeros(theta.shape)\n",
        "\n",
        "    h = sigmoid(X.dot(theta.T))\n",
        "\n",
        "    temp = theta\n",
        "    temp[0] = 0\n",
        "\n",
        "#     J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n",
        "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
        "\n",
        "    grad = (1 / m) * (h - y).dot(X)\n",
        "#     theta = theta - (alpha / m) * (h - y).dot(X)\n",
        "    grad = grad + (lambda_ / m) * temp\n",
        "\n",
        "    return J, grad\n",
        "#    return J, theta"
      ],
      "metadata": {
        "id": "JHf24j0f8aO7"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.3 Vectorización regularizada de la regresión logística\n",
        "\n",
        "Una vez implementada la vectorización para la regresión logística, corresponde agregarar regularización a la función de costo.\n",
        "Para la regresión logística regularizada, la función de costo se define como\n",
        "\n",
        "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\left[ -y^{(i)} \\log \\left(h_\\theta\\left(x^{(i)} \\right)\\right) - \\left( 1 - y^{(i)} \\right) \\log\\left(1 - h_\\theta \\left(x^{(i)} \\right) \\right) \\right] + \\frac{\\lambda}{2m} \\sum_{j=1}^n \\theta_j^2 $$\n",
        "\n",
        "Tomar en cuenta que no debería regularizarse $\\theta_0$ que se usa para el término de sesgo. En consecuencia, la derivada parcial del costo de regresión logística regularizado para $\\theta_j$ se define como\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "& \\frac{\\partial J(\\theta)}{\\partial \\theta_0} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta\\left( x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)}  & \\text{for } j = 0 \\\\\n",
        "& \\frac{\\partial J(\\theta)}{\\partial \\theta_0} = \\left( \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta\\left( x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)} \\right) + \\frac{\\lambda}{m} \\theta_j & \\text{for } j  \\ge 1\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "<div class=\"alert alert-box alert-warning\">\n",
        "** Python/numpy Consejo: ** Al implementar la vectorización para la regresión logística regularizada, a menudo es posible que solo desee sumar y actualizar ciertos elementos de $\\theta$. En `numpy`, puede indexar en las matrices para acceder y actualizar solo ciertos elementos.\n",
        "\n",
        "Por ejemplo, A [:, 3: 5] = B [:, 1: 3] reemplazará las columnas con índice 3 a 5 de A con las columnas con índice 1 a 3 de B.   \n",
        "Para seleccionar columnas (o filas) hasta el final de la matriz, puede dejar el lado derecho de los dos puntos en blanco.\n",
        "Por ejemplo, A [:, 2:] solo devolverá elementos desde $3^{rd}$ a las últimas columnas de $A$.Si deja el tamaño de la mano izquierda de los dos puntos en blanco, seleccionará los elementos del principio de la matriz.\n",
        "Por ejemplo, A [:,: 2] selecciona las dos primeras columnas y es equivalente a A [:, 0: 2]. Además, puede utilizar índices negativos para indexar matrices desde el final.\n",
        "Por lo tanto, A [:,: -1] selecciona todas las columnas de A excepto la última columna, y A [:, -5:] selecciona la columna $5^{th}$ desde el final hasta la última columna.\n",
        "\n",
        "Por lo tanto, podría usar esto junto con las operaciones de suma y potencia ($^{**}$) para calcular la suma de solo los elementos que le interesan (por ejemplo, `np.sum (z[1:]**2)`).\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "4FcoYvaQA48R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4 Clasificacion One-vs-all\n",
        "\n",
        "En esta parte del ejercicio, se implementará la clasificación de uno contra todos mediante el entrenamiento de múltiples clasificadores de regresión logística regularizados, uno para cada una de las clases  𝐾  en nuestro conjunto de datos. En el conjunto de datos de dígitos escritos a mano,  𝐾=10 , pero su código debería funcionar para cualquier valor de  𝐾 .\n",
        "\n",
        "El argumento y de esta función es un vector de etiquetas de 0 a 9. Al entrenar el clasificador para la clase  𝑘∈{0,...,𝐾−1} , querrá un vector K-dimensional de etiquetas  𝑦 , donde  𝑦𝑗 𝑖𝑛0,1  indica si la instancia de entrenamiento  𝑗𝑡ℎ  pertenece a la clase  𝑘   (𝑦𝑗=1) , o si pertenece a una clase diferente  (𝑦𝑗=0) .\n",
        "\n",
        "Además, se utiliza optimize.minimize de scipy para este ejercicio."
      ],
      "metadata": {
        "id": "LWh3F3o39KJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 80% entrenamiento, 20% prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Conjunto de entrenamiento:\", X_train.shape)\n",
        "print(\"Conjunto de prueba:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVY6WmqDDnnV",
        "outputId": "6eb9bceb-e032-4915-f7f9-0ab9acb687c9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de entrenamiento: (80, 16)\n",
            "Conjunto de prueba: (21, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = 7\n",
        "lambda_ = 0.1\n",
        "\n",
        "all_theta = OneVsAllOM(X_train, y_train, num_labels, lambda_)"
      ],
      "metadata": {
        "id": "4YZWTcKUDsaz"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precisión en entrenamiento\n",
        "y_pred_train = predictOneVsAll(all_theta, X_train)\n",
        "print(\"Precisión en entrenamiento: {:.2f}%\".format(np.mean(y_pred_train == y_train) * 100))\n",
        "\n",
        "# Precisión en prueba\n",
        "y_pred_test = predictOneVsAll(all_theta, X_test)\n",
        "print(\"Precisión en prueba: {:.2f}%\".format(np.mean(y_pred_test == y_test) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JPOBCQcDxxA",
        "outputId": "b9023406-9052-4f54-ae23-0bd23ef1430c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión en entrenamiento: 100.00%\n",
            "Precisión en prueba: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def OneVsAll(X, y, num_labels, lambda_=0):\n",
        "    alpha = 0.01\n",
        "    num_iters = 3000  # menos iteraciones, más práctico en zoo (101 ejemplos)\n",
        "\n",
        "    m, n = X.shape\n",
        "    all_theta = np.zeros((num_labels, n + 1))\n",
        "\n",
        "    # Agregar columna de unos a X\n",
        "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
        "\n",
        "    for c in range(num_labels):\n",
        "        initial_theta = np.zeros(n + 1)\n",
        "\n",
        "        # Etiquetas binarias: 1 si clase == c, 0 en caso contrario\n",
        "        y_actual = np.where(y == c, 1, 0)\n",
        "\n",
        "        theta, J_history = descensoGradiente(initial_theta, X, y_actual,\n",
        "                                             alpha, num_iters, lambda_)\n",
        "\n",
        "        all_theta[c] = theta\n",
        "\n",
        "        # Opcional: graficar convergencia\n",
        "        plt.plot(np.arange(len(J_history)), J_history, lw=2, label=f\"Clase {c}\")\n",
        "\n",
        "    plt.xlabel('Iteraciones')\n",
        "    plt.ylabel('Costo J')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return all_theta\n",
        ""
      ],
      "metadata": {
        "id": "MjcQ3r369Kfo"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import optimize\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1.0 / (1.0 + np.exp(-z))\n",
        "\n",
        "def lrCostFunction(theta, X, y, lambda_):\n",
        "    \"\"\"\n",
        "    Función de costo regularizada para regresión logística.\n",
        "    \"\"\"\n",
        "    m = len(y)\n",
        "    h = sigmoid(X.dot(theta))\n",
        "\n",
        "    # costo\n",
        "    J = (-1/m) * (y.T.dot(np.log(h)) + (1-y).T.dot(np.log(1-h)))\n",
        "    J += (lambda_/(2*m)) * np.sum(np.square(theta[1:]))\n",
        "\n",
        "    # gradiente\n",
        "    grad = (1/m) * (X.T.dot(h - y))\n",
        "    grad[1:] += (lambda_/m) * theta[1:]\n",
        "\n",
        "    return J, grad\n",
        "\n",
        "\n",
        "def OneVsAllOM(X, y, num_labels, lambda_):\n",
        "    \"\"\"\n",
        "    Entrena num_labels clasificadores logísticos y retorna\n",
        "    la matriz all_theta con cada clasificador en una fila.\n",
        "    \"\"\"\n",
        "    m, n = X.shape\n",
        "    all_theta = np.zeros((num_labels, n + 1))\n",
        "\n",
        "    # Agregar columna de unos (bias)\n",
        "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
        "\n",
        "    for c in np.arange(num_labels):\n",
        "        initial_theta = np.zeros(n + 1)\n",
        "        options = {'maxiter': 50}\n",
        "\n",
        "        res = optimize.minimize(lrCostFunction,\n",
        "                                initial_theta,\n",
        "                                args=(X, (y == c).astype(int), lambda_),\n",
        "                                jac=True,\n",
        "                                method='CG',\n",
        "                                options=options)\n",
        "\n",
        "        all_theta[c] = res.x\n",
        "\n",
        "    return all_theta"
      ],
      "metadata": {
        "id": "wUNxNDxA9JzJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regularización\n",
        "lambda_ = 0.1\n",
        "\n",
        "# Entrenar One-vs-All con optimización\n",
        "all_theta = OneVsAllOM(X, y, num_labels, lambda_)\n",
        "\n",
        "# Mostrar dimensiones de la matriz de parámetros\n",
        "print(all_theta.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2DxQrLW-zaR",
        "outputId": "448f0ba6-9537-4561-e750-4f67b4660b0b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6WuoKjH-2k1",
        "outputId": "afd1135f-d77b-4d34-f8bb-0777a9b8e264"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.48436660e+00  1.51562269e+00 -5.36634974e-01 -1.52249261e+00\n",
            "   2.29657787e+00 -2.53161267e-01  5.73916883e-02  7.69750275e-02\n",
            "   4.23983899e-01  4.71943834e-01  7.73444748e-01 -4.75189016e-01\n",
            "   2.46812659e-02  4.43840337e-02  2.91057337e-01  1.49260772e-01\n",
            "   7.20096306e-01]\n",
            " [-4.86562173e+00 -4.92065596e-01  2.81067076e+00  3.40172676e-01\n",
            "  -4.40272600e-01  7.56529991e-01 -8.78863783e-03  1.34124028e-01\n",
            "  -1.06861978e+00  6.50029751e-01  4.37792778e-01 -2.68475843e-01\n",
            "  -4.12862127e-01 -4.96119117e-01  6.17191396e-01  1.12915629e-01\n",
            "   9.43154998e-02]\n",
            " [-6.58180424e+00 -1.76911474e+00 -2.39922526e+00  2.47820279e-01\n",
            "  -1.78862507e+00 -8.28311503e-01 -1.96355073e+00 -2.10562183e-01\n",
            "   2.17629932e-01  1.84141365e+00 -4.80069579e-01  6.07887144e-01\n",
            "  -2.19462849e+00 -7.18937694e-01  1.51520883e+00 -3.86257520e-01\n",
            "  -2.86452955e-02]\n",
            " [-7.37730182e+00 -1.93229170e-01 -2.52579367e-01  1.33667309e+00\n",
            "  -9.00193449e-01 -1.84135012e-01  4.21861179e-01 -2.43796784e-01\n",
            "   6.59806392e-01  5.62355465e-01 -1.72196509e+00 -2.52214007e-01\n",
            "   1.84392295e+00 -6.25797878e-01  6.18653680e-01  8.13359689e-02\n",
            "  -8.36332431e-03]\n",
            " [-7.26483747e+00 -6.82464116e-01 -6.82396480e-01  7.65919103e-01\n",
            "  -7.13763883e-01 -5.92709104e-01  2.19226618e+00  3.59822717e-02\n",
            "   1.45544399e+00  1.03443759e+00  1.49800977e+00  7.03281509e-02\n",
            "  -7.80949488e-01  1.00932058e+00 -7.57323644e-01 -1.66387221e-01\n",
            "  -8.19197619e-01]\n",
            " [-9.12502365e+00  2.97550379e-01 -5.00483315e-01  9.11041008e-01\n",
            "  -2.67021504e-01  1.09108117e+00 -1.14896112e+00 -9.94279453e-01\n",
            "  -3.98882902e-01 -1.07804562e+00  1.20314569e+00 -3.56348491e-01\n",
            "  -4.71518727e-03  2.07411517e+00 -1.34286571e+00 -7.25436640e-02\n",
            "  -5.89560077e-01]\n",
            " [-8.15816548e+00 -3.88814230e-01 -4.07965639e-01 -6.42799227e-01\n",
            "  -1.18081487e-01 -1.63825333e+00  3.45975363e-01  1.40200018e+00\n",
            "  -2.10844537e+00 -3.18491964e+00 -7.88197033e-01  4.38941878e-01\n",
            "  -5.92266856e-01 -1.36945448e+00 -1.83448932e-01 -1.50973860e-01\n",
            "   3.44443093e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4.1 Prediccion One-vs-all\n",
        "\n",
        "Después de entrenar el clasificador de one-vs-all, se puede usarlo para predecir el dígito contenido en una imagen determinada. Para cada entrada, debe calcular la \"probabilidad\" de que pertenezca a cada clase utilizando los clasificadores de regresión logística entrenados. La función de predicción one-vs-all seleccionará la clase para la cual el clasificador de regresión logística correspondiente genera la probabilidad más alta y devolverá la etiqueta de clase (0, 1, ..., K-1) como la predicción para el ejemplo de entrada."
      ],
      "metadata": {
        "id": "vGOpPzUx_HiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predictOneVsAll(all_theta, X):\n",
        "    \"\"\"\n",
        "    Devuelve un vector de predicciones para cada ejemplo en la matriz X.\n",
        "    - all_theta: matriz (K x n+1) con los parámetros entrenados.\n",
        "    - X: matriz (m x n) con las características (sin el bias).\n",
        "    \"\"\"\n",
        "    m = X.shape[0]\n",
        "    num_labels = all_theta.shape[0]\n",
        "\n",
        "    # Add ones to the X data matrix\n",
        "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
        "\n",
        "    # Probabilidades para cada clase\n",
        "    probs = sigmoid(X.dot(all_theta.T))\n",
        "\n",
        "    # Predicción = índice de la probabilidad mayor\n",
        "    p = np.argmax(probs, axis=1)\n",
        "\n",
        "    return p"
      ],
      "metadata": {
        "id": "9Cw72YqB_H8B"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez que haya terminado, se llama a la función predictOneVsAll usando el valor aprendido de  𝜃 . Debería apreciarse que la precisión del conjunto de entrenamiento es de aproximadamente 95,1% (es decir, clasifica correctamente el 95,1% de los ejemplos del conjunto de entrenamiento)."
      ],
      "metadata": {
        "id": "I01mAHVD9JVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)  # (101, 16)\n",
        "\n",
        "pred = predictOneVsAll(all_theta, X)\n",
        "print('Precisión del conjunto de entrenamiento: {:.2f}%'.format(np.mean(pred == y) * 100))\n",
        "\n",
        "# Tomamos el último animal como prueba\n",
        "XPrueba = X[100:101, :].copy()\n",
        "print(XPrueba.shape)  # (1, 16)\n",
        "\n",
        "# Agregar bias\n",
        "XPrueba = np.concatenate([np.ones((XPrueba.shape[0], 1)), XPrueba], axis=1)\n",
        "print(XPrueba.shape)  # (1, 17)\n",
        "\n",
        "# Predicción\n",
        "p = np.argmax(sigmoid(XPrueba.dot(all_theta.T)), axis=1)\n",
        "print(\"Predicción:\", p)\n",
        "\n",
        "# Clase real\n",
        "print(\"Etiqueta real:\", y[100:101])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ymvvt0L_rht",
        "outputId": "02b69b55-dd6c-4664-a519-616dba1fc85b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(101, 16)\n",
            "Precisión del conjunto de entrenamiento: 100.00%\n",
            "(1, 16)\n",
            "(1, 17)\n",
            "Predicción: [1]\n",
            "Etiqueta real: [1]\n"
          ]
        }
      ]
    }
  ]
}